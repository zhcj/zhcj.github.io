<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta http-equiv=pragma content=no-cache>
<link href="css/bootstrap.min.css" rel="stylesheet">
<link rel="shortcut icon" href="favicon.ico">
<link rel="bookmark" href="favicon.ico">
<title>Ollama+DeepSeek+open-webui安装配置</title>
</head>
<body>
<div class="container">
<p><a href="index.html">返回首页</a></p>
<h2 align=center>Ollama+DeepSeek+open-webui/chatbox安装配置</h2>
<p>注：Mac mini/Windows11/AlmaLinux9测试通过。</p>
<p><b>一、安装Ollama，详见<a href="https://ollama.com" target="_blank">Ollama官网</a></b></p>
<p>1、各平台安装Ollama，下载安装包安装或使用官方脚本</p>
<p>2、Linux命令行手动操作</p>
<p>2.1、下载ollama（根据你的系统架构下载相应版本），解压</p>
<pre>wget https://github.com/ollama/ollama/releases/download/v0.5.13/ollama-linux-amd64.tgz
tar xvf ollama-inux-amd64.tgz -C /usr</pre>
<p>2.2、添加ollama用户及组，将当前用户加入ollama组</p>
<pre>useradd -r -s /bin/false -U -m -d /usr/share/ollama ollama
usermod -a -G ollama $(whoami)</pre>
<p>2.3、创建启动脚本</p>
<pre>cat > /lib/systemd/system/ollama.service << "EOF"
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
#以下两行将11434端口打开，为了安全，需要用防火墙限制IP等方式进行控制，如安装open-webui客户端，将下面两行注释即可
Environment="OLLAMA_HOST=0.0.0.0"
Environment="OLLAMA_ORIGINS=*"
ExecStart=/usr/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="PATH=$PATH"

[Install]
WantedBy=default.target
EOF
</pre>
<p>2.4、启动并添加开机启动</p>
<pre>systemctl start ollama
systemctl enable ollama
</pre>
<p><b>二、Ollama安装deepseek</b></p>
<p>所有平台均可以运行以下命令安装</p>
<pre>ollama run deepseek-r1:8b</pre>
<p>注：<p>
<p>#<a href="https://ollama.com/models" target="_blank">https://ollama.com/models</a>可以下载各种大模型；<p>
<p>#8b中的b是billion（10亿），也就是80亿个参数。<p>
<p><b>三、安装客户端</b></p>
<p>说明：</p>
<p>#以下软件均在快速开发迭代中（甚至一天多个版本发布），请随时关注其官方网站；</p>
<p>#所有客户端均需要调用ollama的11434端口，特别要注意服务端的安全；</p>
<p>#提供web端的，如open-webui，服务端可以关闭11434端口和open-webui的8080端口，将8080端口用nginx转发至其他端口，更安全。</p>
<p>1、open-webui，服务端安装，适合多用户，浏览器打开网页即可使用</p>
<p>各平台安装python-3.11（必须是此版本），安装好运行行以下命令</p>
<pre>
pip install open-webui
open-webui serve
</pre>
<p>注：<p>
<p>#服务器端安装好，第一次网页打开很慢，打开后需要设置用户名、邮箱、密码来中注册管理员账号；<p>
<p>#管理员登录后，建议进行以下设置：设置外部链接来连接ollama上的大模型、将大模型由privacy设置为public、开放账号注册；<p>
<p>#用户打开http://服务端IP:8080，用邮箱和密码注册，登录使用。<p>
<p>2、chatbox，支持所有平台，有移动端<p>
<p>2.1、chatbox安装包，下载地址：<a href="https://chatboxai.app" target="_blank">https://chatboxai.app</a></p>
<p>2.2、chatbox源码编译，支持所有平台</p>
<p>安装nodejs-20（必须是此版本），运行行以下命令</p>
<pre>
git clone https://github.com/Bin-Huang/chatbox
cd chatbox
#将package.json中的tailwindcss版本由4.0.0改为3.4，手动修改可使用以下命令
sed -i "" "s/\"tailwindcss\": \"\^4\.0\.0\"/\"tailwindcss\": \"\^3\.4\"/g" package.json
npm install
npm run dev
</pre>
<p>3、cherry studio，支持所有平台，但无移动端<p>
<p>3.1、cherry studio，下载地址：<a href="https://cherry-ai.com/download" target="_blank">https://cherry-ai.com/download</a></p>
<p>3.2、cherry studio源码编译，支持所有平台</p>
<p>安装yarn最新版本，目前是yarn-4.7，运行行以下命令</p>
<pre>
#yarn安装
corepack enable
yarn set version stable
git clone https://github.com/CherryHQ/cherry-studio
cd cherry-studio
yarn
yarn run dev
</pre>
<p><a href="index.html">返回首页</a></p>
<p align="center">&copy; 2016-2025 清风的个人笔记</p>
</div>
</body>
</html>
